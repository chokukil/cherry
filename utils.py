from __future__ import annotations
from typing import Any, Dict, List, Callable, Optional, Sequence
from dataclasses import dataclass
import uuid

from langchain_core.messages import (
    AIMessageChunk,
    AIMessage,
    BaseMessage,
    HumanMessage,
    SystemMessage
)
from langchain_core.runnables import RunnableConfig
from langchain_core.agents import AgentAction, AgentFinish, AgentStep
from langchain.agents.output_parsers.tools import ToolAgentAction
from langchain_openai import ChatOpenAI
from langgraph.graph.state import CompiledStateGraph
# +++ Version-compatible import for StructuredTool +++
try:  # LangChain â‰¥ 0.3.x (í˜„ì¬ ì„¤ì¹˜ëœ 0.3.25 ê¸°ì¤€)
    from langchain_core.tools.structured import StructuredTool
except ImportError:              # 0.2.x â†’ re-export ê²½ë¡œ
    try:
        from langchain.tools.structured import StructuredTool
    except ImportError:          # 0.1.x ì´í•˜ ë ˆê±°ì‹œ
        from langchain.tools import StructuredTool
import inspect, json, asyncio, concurrent.futures as _fut
from langchain_core.tools import Tool
import logging
from langchain_core.tools.structured import StructuredTool   # â¬… í•„ìš” ì‹œ import


def random_uuid():
    return str(uuid.uuid4())


async def astream_graph(
    graph: CompiledStateGraph,
    inputs: dict,
    config: Optional[RunnableConfig] = None,
    node_names: List[str] = [],
    callback: Optional[Callable] = None,
    stream_mode: str = "messages",
    include_subgraphs: bool = False,
) -> Dict[str, Any]:
    """
    LangGraphì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ê³  ì§ì ‘ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
        config (Optional[RunnableConfig]): ì‹¤í–‰ ì„¤ì • (ì„ íƒì )
        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        callback (Optional[Callable], optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
            ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": Any} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        stream_mode (str, optional): ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ("messages" ë˜ëŠ” "updates"). ê¸°ë³¸ê°’ì€ "messages"
        include_subgraphs (bool, optional): ì„œë¸Œê·¸ë˜í”„ í¬í•¨ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ False

    Returns:
        Dict[str, Any]: ìµœì¢… ê²°ê³¼ (ì„ íƒì )
    """
    config = config or {}
    final_result = {}

    def format_namespace(namespace):
        return namespace[-1].split(":")[0] if len(namespace) > 0 else "root graph"

    prev_node = ""

    if stream_mode == "messages":
        async for chunk_msg, metadata in graph.astream(
            inputs, config, stream_mode=stream_mode
        ):
            curr_node = metadata["langgraph_node"]
            final_result = {"node": curr_node, "content": chunk_msg, "metadata": metadata}

            # node_namesê°€ ë¹„ì–´ìˆê±°ë‚˜ í˜„ì¬ ë…¸ë“œê°€ node_namesì— ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
            if not node_names or curr_node in node_names:
                # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                if callback:
                    result = callback({"node": curr_node, "content": chunk_msg})
                    if hasattr(result, "__await__"):
                        await result
                # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                else:
                    # ë…¸ë“œê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶œë ¥
                    if curr_node != prev_node:
                        print("\n" + "=" * 50)
                        print(f"ğŸ”„ Node: \033[1;36m{curr_node}\033[0m ğŸ”„")
                        print("- " * 25)
                    
                    # Claude/Anthropic ëª¨ë¸ì˜ í† í° ì²­í¬ ì²˜ë¦¬ - í•­ìƒ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                    if hasattr(chunk_msg, 'content'):
                        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ content (Anthropic/Claude ìŠ¤íƒ€ì¼)
                        if isinstance(chunk_msg.content, list):
                            for item in chunk_msg.content:
                                if isinstance(item, dict) and 'text' in item:
                                    print(item['text'], end="", flush=True)
                        # ë¬¸ìì—´ í˜•íƒœì˜ content
                        elif isinstance(chunk_msg.content, str):
                            print(chunk_msg.content, end="", flush=True)
                    # ê·¸ ì™¸ í˜•íƒœì˜ chunk_msg ì²˜ë¦¬
                    else:
                        print(chunk_msg, end="", flush=True)

                prev_node = curr_node

    elif stream_mode == "updates":
        # ì—ëŸ¬ ìˆ˜ì •: ì–¸íŒ¨í‚¹ ë°©ì‹ ë³€ê²½
        # REACT ì—ì´ì „íŠ¸ ë“± ì¼ë¶€ ê·¸ë˜í”„ì—ì„œëŠ” ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜í•¨
        async for chunk in graph.astream(
            inputs, config, stream_mode=stream_mode, subgraphs=include_subgraphs
        ):
            # ë°˜í™˜ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬ ë°©ë²• ë¶„ê¸°
            if isinstance(chunk, tuple) and len(chunk) == 2:
                # ê¸°ì¡´ ì˜ˆìƒ í˜•ì‹: (namespace, chunk_dict)
                namespace, node_chunks = chunk
            else:
                # ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜í•˜ëŠ” ê²½ìš° (REACT ì—ì´ì „íŠ¸ ë“±)
                namespace = []  # ë¹ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (ë£¨íŠ¸ ê·¸ë˜í”„)
                node_chunks = chunk  # chunk ìì²´ê°€ ë…¸ë“œ ì²­í¬ ë”•ì…”ë„ˆë¦¬
            
            # ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸í•˜ê³  í•­ëª© ì²˜ë¦¬
            if isinstance(node_chunks, dict):
                for node_name, node_chunk in node_chunks.items():
                    final_result = {"node": node_name, "content": node_chunk, "namespace": namespace}
                    
                    # node_namesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í•„í„°ë§
                    if len(node_names) > 0 and node_name not in node_names:
                        continue

                    # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                    if callback is not None:
                        result = callback({"node": node_name, "content": node_chunk})
                        if hasattr(result, "__await__"):
                            await result
                    # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                    else:
                        # ë…¸ë“œê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶œë ¥ (messages ëª¨ë“œì™€ ë™ì¼í•˜ê²Œ)
                        if node_name != prev_node:
                            print("\n" + "=" * 50)
                            print(f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m ğŸ”„")
                            print("- " * 25)
                        
                        # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥ - í…ìŠ¤íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì²˜ë¦¬
                        if isinstance(node_chunk, dict):
                            for k, v in node_chunk.items():
                                if isinstance(v, BaseMessage):
                                    # BaseMessageì˜ content ì†ì„±ì´ í…ìŠ¤íŠ¸ë‚˜ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°ë¥¼ ì²˜ë¦¬
                                    if hasattr(v, 'content'):
                                        if isinstance(v.content, list):
                                            for item in v.content:
                                                if isinstance(item, dict) and 'text' in item:
                                                    print(item['text'], end="", flush=True)
                                        else:
                                            print(v.content, end="", flush=True)
                                    else:
                                        v.pretty_print()
                                elif isinstance(v, list):
                                    for list_item in v:
                                        if isinstance(list_item, BaseMessage):
                                            if hasattr(list_item, 'content'):
                                                if isinstance(list_item.content, list):
                                                    for item in list_item.content:
                                                        if isinstance(item, dict) and 'text' in item:
                                                            print(item['text'], end="", flush=True)
                                                else:
                                                    print(list_item.content, end="", flush=True)
                                            else:
                                                list_item.pretty_print()
                                        elif isinstance(list_item, dict) and 'text' in list_item:
                                            print(list_item['text'], end="", flush=True)
                                        else:
                                            print(list_item, end="", flush=True)
                                elif isinstance(v, dict) and 'text' in v:
                                    print(v['text'], end="", flush=True)
                                else:
                                    print(v, end="", flush=True)
                        elif node_chunk is not None:
                            if hasattr(node_chunk, "__iter__") and not isinstance(node_chunk, str):
                                for item in node_chunk:
                                    if isinstance(item, dict) and 'text' in item:
                                        print(item['text'], end="", flush=True)
                                    else:
                                        print(item, end="", flush=True)
                            else:
                                print(node_chunk, end="", flush=True)
                        
                        # êµ¬ë¶„ì„ ì„ ì—¬ê¸°ì„œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ (messages ëª¨ë“œì™€ ë™ì¼í•˜ê²Œ)
                        
                    prev_node = node_name
            else:
                # ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì „ì²´ ì²­í¬ ì¶œë ¥
                print("\n" + "=" * 50)
                print(f"ğŸ”„ Raw output ğŸ”„")
                print("- " * 25)
                print(node_chunks, end="", flush=True)
                # êµ¬ë¶„ì„ ì„ ì—¬ê¸°ì„œ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
                final_result = {"content": node_chunks}

    else:
        raise ValueError(
            f"Invalid stream_mode: {stream_mode}. Must be 'messages' or 'updates'."
        )
    
    # í•„ìš”ì— ë”°ë¼ ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return final_result

async def ainvoke_graph(
    graph: CompiledStateGraph,
    inputs: dict,
    config: Optional[RunnableConfig] = None,
    node_names: List[str] = [],
    callback: Optional[Callable] = None,
    include_subgraphs: bool = True,
) -> Dict[str, Any]:
    """
    LangGraph ì•±ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
        config (Optional[RunnableConfig]): ì‹¤í–‰ ì„¤ì • (ì„ íƒì )
        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        callback (Optional[Callable], optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
            ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": Any} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        include_subgraphs (bool, optional): ì„œë¸Œê·¸ë˜í”„ í¬í•¨ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ True

    Returns:
        Dict[str, Any]: ìµœì¢… ê²°ê³¼ (ë§ˆì§€ë§‰ ë…¸ë“œì˜ ì¶œë ¥)
    """
    config = config or {}
    final_result = {}

    def format_namespace(namespace):
        return namespace[-1].split(":")[0] if len(namespace) > 0 else "root graph"

    # subgraphs ë§¤ê°œë³€ìˆ˜ë¥¼ í†µí•´ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ë„ í¬í•¨
    async for chunk in graph.astream(
        inputs, config, stream_mode="updates", subgraphs=include_subgraphs
    ):
        # ë°˜í™˜ í˜•ì‹ì— ë”°ë¼ ì²˜ë¦¬ ë°©ë²• ë¶„ê¸°
        if isinstance(chunk, tuple) and len(chunk) == 2:
            # ê¸°ì¡´ ì˜ˆìƒ í˜•ì‹: (namespace, chunk_dict)
            namespace, node_chunks = chunk
        else:
            # ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë§Œ ë°˜í™˜í•˜ëŠ” ê²½ìš° (REACT ì—ì´ì „íŠ¸ ë“±)
            namespace = []  # ë¹ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (ë£¨íŠ¸ ê·¸ë˜í”„)
            node_chunks = chunk  # chunk ìì²´ê°€ ë…¸ë“œ ì²­í¬ ë”•ì…”ë„ˆë¦¬
        
        # ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸í•˜ê³  í•­ëª© ì²˜ë¦¬
        if isinstance(node_chunks, dict):
            for node_name, node_chunk in node_chunks.items():
                final_result = {"node": node_name, "content": node_chunk, "namespace": namespace}
                
                # node_namesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í•„í„°ë§
                if node_names and node_name not in node_names:
                    continue

                # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                if callback is not None:
                    result = callback({"node": node_name, "content": node_chunk})
                    # ì½”ë£¨í‹´ì¸ ê²½ìš° await
                    if hasattr(result, "__await__"):
                        await result
                # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                else:
                    print("\n" + "=" * 50)
                    formatted_namespace = format_namespace(namespace)
                    if formatted_namespace == "root graph":
                        print(f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m ğŸ”„")
                    else:
                        print(
                            f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m in [\033[1;33m{formatted_namespace}\033[0m] ğŸ”„"
                        )
                    print("- " * 25)

                    # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥
                    if isinstance(node_chunk, dict):
                        for k, v in node_chunk.items():
                            if isinstance(v, BaseMessage):
                                v.pretty_print()
                            elif isinstance(v, list):
                                for list_item in v:
                                    if isinstance(list_item, BaseMessage):
                                        list_item.pretty_print()
                                    else:
                                        print(list_item)
                            elif isinstance(v, dict):
                                for node_chunk_key, node_chunk_value in v.items():
                                    print(f"{node_chunk_key}:\n{node_chunk_value}")
                            else:
                                print(f"\033[1;32m{k}\033[0m:\n{v}")
                    elif node_chunk is not None:
                        if hasattr(node_chunk, "__iter__") and not isinstance(node_chunk, str):
                            for item in node_chunk:
                                print(item)
                        else:
                            print(node_chunk)
                    print("=" * 50)
        else:
            # ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš° ì „ì²´ ì²­í¬ ì¶œë ¥
            print("\n" + "=" * 50)
            print(f"ğŸ”„ Raw output ğŸ”„")
            print("- " * 25)
            print(node_chunks)
            print("=" * 50)
            final_result = {"content": node_chunks}
    
    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return final_result

FOLLOWUP_PROMPT = """You are an AI assistant that proposes short, helpful follow-up
questions the user might click next. Return 3 suggestions, each on a new line."""

def get_followup_llm(model_name: str,
                     temperature: float,
                     api_key: str,
                     base_url: str):
    """pages ì½”ë“œì—ì„œ ì“°ëŠ” ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ë„˜ê²¨ ë°›ì•„ ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±."""
    return ChatOpenAI(
        model=model_name,
        temperature=temperature,
        max_tokens=64,
        api_key=api_key,
        base_url=base_url,
    )

async def generate_followups(llm, last_answer: str, k: int = 3) -> list[str]:
    """ë§ˆì§€ë§‰ assistant ë‹µë³€ìœ¼ë¡œë¶€í„° kê°œì˜ follow-up ë¬¸ì¥ ìƒì„±."""
    resp = await llm.ainvoke([
        SystemMessage(content=FOLLOWUP_PROMPT),
        HumanMessage(content=last_answer),
    ])
    return [l.strip("-â€¢ ").rstrip()
            for l in resp.content.splitlines()
            if l.strip()][:k]

def tool_callback(tool) -> None:
    print("[ë„êµ¬ í˜¸ì¶œ]")
    print(f"Tool: {tool.get('tool')}")  # ì‚¬ìš©ëœ ë„êµ¬ì˜ ì´ë¦„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    if tool_input := tool.get("tool_input"):
        for k, v in tool_input.items():
            print(f"{k}: {v}")
    print(f"Log: {tool.get('log')}")

def observation_callback(observation) -> None:
    print("[ê´€ì°° ë‚´ìš©]")
    print(f"Observation: {observation.get('observation')}")

def result_callback(result: str) -> None:
    print("[ìµœì¢… ë‹µë³€]")
    print(result)

@dataclass
class AgentCallbacks:
    """
    ì—ì´ì „íŠ¸ ì½œë°± í•¨ìˆ˜ë“¤ì„ í¬í•¨í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

    Attributes:
        tool_callback (Callable[[Dict[str, Any]], None]): ë„êµ¬ ì‚¬ìš© ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜
        observation_callback (Callable[[Dict[str, Any]], None]): ê´€ì°° ê²°ê³¼ ì²˜ë¦¬ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜
        result_callback (Callable[[str], None]): ìµœì¢… ê²°ê³¼ ì²˜ë¦¬ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°± í•¨ìˆ˜
    """
    tool_callback: Callable[[Dict[str, Any]], None] = tool_callback
    observation_callback: Callable[[Dict[str, Any]], None] = observation_callback
    result_callback: Callable[[str], None] = result_callback

class AgentStreamParser:
    """
    ì—ì´ì „íŠ¸ì˜ ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ì„ íŒŒì‹±í•˜ê³  ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self, callbacks: AgentCallbacks = AgentCallbacks()):
        self.callbacks = callbacks
        self.output = None

    def process_agent_steps(self, step: Dict[str, Any]) -> None:
        if "actions" in step:
            self._process_actions(step["actions"])
        elif "steps" in step:
            self._process_observations(step["steps"])
        elif "output" in step:
            self._process_result(step["output"])

    def _process_actions(self, actions: List[Any]) -> None:
        for action in actions:
            if isinstance(action, (AgentAction, ToolAgentAction)) and hasattr(
                action, "tool"
            ):
                self._process_tool_call(action)

    def _process_tool_call(self, action: Any) -> None:
        tool_action = {
            "tool": getattr(action, "tool", None),
            "tool_input": getattr(action, "tool_input", None),
            "log": getattr(action, "log", None),
        }
        self.callbacks.tool_callback(tool_action)

    def _process_observations(self, observations: List[Any]) -> None:
        for observation in observations:
            observation_dict = {}
            if isinstance(observation, AgentStep):
                observation_dict["observation"] = getattr(
                    observation, "observation", None
                )
            self.callbacks.observation_callback(observation_dict)

    def _process_result(self, result: str) -> None:
        self.callbacks.result_callback(result)
        self.output = result

def pretty_print_messages(messages: list[BaseMessage]):
    for message in messages:
        message.pretty_print()

# ê° ê¹Šì´ ìˆ˜ì¤€ì— ëŒ€í•´ ë¯¸ë¦¬ ì •ì˜ëœ ìƒ‰ìƒ (ANSI ì´ìŠ¤ì¼€ì´í”„ ì½”ë“œ ì‚¬ìš©)
depth_colors = {
    1: "\033[96m",  # ë°ì€ ì²­ë¡ìƒ‰ (ëˆˆì— ì˜ ë„ëŠ” ì²« ê³„ì¸µ)
    2: "\033[93m",  # ë…¸ë€ìƒ‰ (ë‘ ë²ˆì§¸ ê³„ì¸µ)
    3: "\033[94m",  # ë°ì€ ì´ˆë¡ìƒ‰ (ì„¸ ë²ˆì§¸ ê³„ì¸µ)
    4: "\033[95m",  # ë³´ë¼ìƒ‰ (ë„¤ ë²ˆì§¸ ê³„ì¸µ)
    5: "\033[92m",  # ë°ì€ íŒŒë€ìƒ‰ (ë‹¤ì„¯ ë²ˆì§¸ ê³„ì¸µ)
    "default": "\033[96m",  # ê¸°ë³¸ê°’ì€ ë°ì€ ì²­ë¡ìƒ‰ìœ¼ë¡œ
    "reset": "\033[0m",  # ê¸°ë³¸ ìƒ‰ìƒìœ¼ë¡œ ì¬ì„¤ì •
}

def is_terminal_dict(data):
    """ë§ë‹¨ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    if not isinstance(data, dict):
        return False
    for value in data.values():
        if isinstance(value, (dict, list)) or hasattr(value, "__dict__"):
            return False
    return True

def format_terminal_dict(data):
    """ë§ë‹¨ ë”•ì…”ë„ˆë¦¬ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    items = []
    for key, value in data.items():
        if isinstance(value, str):
            items.append(f'"{key}": "{value}"')
        else:
            items.append(f'"{key}": {value}')
    return "{" + ", ".join(items) + "}"

def _display_message_tree(data, indent=0, node=None, is_root=False):
    """
    JSON ê°ì²´ì˜ íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ íƒ€ì… ì •ë³´ ì—†ì´ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    spacing = " " * indent * 4
    color = depth_colors.get(indent + 1, depth_colors["default"])

    if isinstance(data, dict):
        if not is_root and node is not None:
            if is_terminal_dict(data):
                print(
                    f'{spacing}{color}{node}{depth_colors["reset"]}: {format_terminal_dict(data)}'
                )
            else:
                print(f'{spacing}{color}{node}{depth_colors["reset"]}:')
                for key, value in data.items():
                    _display_message_tree(value, indent + 1, key)
        else:
            for key, value in data.items():
                _display_message_tree(value, indent + 1, key)

    elif isinstance(data, list):
        if not is_root and node is not None:
            print(f'{spacing}{color}{node}{depth_colors["reset"]}:')

        for index, item in enumerate(data):
            print(f'{spacing}    {color}index [{index}]{depth_colors["reset"]}')
            _display_message_tree(item, indent + 1)

    elif hasattr(data, "__dict__") and not is_root:
        if node is not None:
            print(f'{spacing}{color}{node}{depth_colors["reset"]}:')
        _display_message_tree(data.__dict__, indent)

    else:
        if node is not None:
            if isinstance(data, str):
                value_str = f'"{data}"'
            else:
                value_str = str(data)

            print(f'{spacing}{color}{node}{depth_colors["reset"]}: {value_str}')

def display_message_tree(message):
    """
    ë©”ì‹œì§€ íŠ¸ë¦¬ë¥¼ í‘œì‹œí•˜ëŠ” ì£¼ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    if isinstance(message, BaseMessage):
        _display_message_tree(message.__dict__, is_root=True)
    else:
        _display_message_tree(message, is_root=True)

class ToolChunkHandler:
    """Tool Message ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ê³  ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self._reset_state()

    def _reset_state(self) -> None:
        """ìƒíƒœ ì´ˆê¸°í™”"""
        self.gathered = None
        self.first = True
        self.current_node = None
        self.current_namespace = None

    def _should_reset(self, node: str | None, namespace: str | None) -> bool:
        """ìƒíƒœ ë¦¬ì…‹ ì—¬ë¶€ í™•ì¸"""
        # íŒŒë¼ë¯¸í„°ê°€ ëª¨ë‘ Noneì¸ ê²½ìš° ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
        if node is None and namespace is None:
            return False

        # nodeë§Œ ì„¤ì •ëœ ê²½ìš°
        if node is not None and namespace is None:
            return self.current_node != node

        # namespaceë§Œ ì„¤ì •ëœ ê²½ìš°
        if namespace is not None and node is None:
            return self.current_namespace != namespace

        # ë‘˜ ë‹¤ ì„¤ì •ëœ ê²½ìš°
        return self.current_node != node or self.current_namespace != namespace

    def process_message(
        self,
        chunk: AIMessageChunk,
        node: str | None = None,
        namespace: str | None = None,
    ) -> None:
        """
        ë©”ì‹œì§€ ì²­í¬ ì²˜ë¦¬

        Args:
            chunk: ì²˜ë¦¬í•  AI ë©”ì‹œì§€ ì²­í¬
            node: í˜„ì¬ ë…¸ë“œëª… (ì„ íƒì‚¬í•­)
            namespace: í˜„ì¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (ì„ íƒì‚¬í•­)
        """
        if self._should_reset(node, namespace):
            self._reset_state()

        self.current_node = node if node is not None else self.current_node
        self.current_namespace = (
            namespace if namespace is not None else self.current_namespace
        )

        self._accumulate_chunk(chunk)
        return self._display_tool_calls()

    def _accumulate_chunk(self, chunk: AIMessageChunk) -> None:
        """ì²­í¬ ëˆ„ì """
        self.gathered = chunk if self.first else self.gathered + chunk
        self.first = False

    def _display_tool_calls(self) -> None:
        """ë„êµ¬ í˜¸ì¶œ ì •ë³´ ì¶œë ¥"""
        if (
            self.gathered
            and not self.gathered.content
            and self.gathered.tool_call_chunks
            and self.gathered.tool_calls
        ):
            return self.gathered.tool_calls[0]["args"]

def get_role_from_messages(msg):
    if isinstance(msg, HumanMessage):
        return "user"
    elif isinstance(msg, AIMessage):
        return "assistant"
    else:
        return "assistant"

def messages_to_history(messages):
    return "\n".join(
        [f"{get_role_from_messages(msg)}: {msg.content}" for msg in messages]
    )

def stream_graph(
    graph: CompiledStateGraph,
    inputs: dict,
    config: RunnableConfig,
    node_names: List[str] = [],
    callback: Callable = None,
):
    """
    LangGraphì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
        config (RunnableConfig): ì‹¤í–‰ ì„¤ì •
        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        callback (Callable, optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
            ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": str} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.

    Returns:
        None: í•¨ìˆ˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì¶œë ¥ë§Œ í•˜ê³  ë°˜í™˜ê°’ì€ ì—†ìŠµë‹ˆë‹¤.
    """
    prev_node = ""
    for chunk_msg, metadata in graph.stream(inputs, config, stream_mode="messages"):
        curr_node = metadata["langgraph_node"]

        # node_namesê°€ ë¹„ì–´ìˆê±°ë‚˜ í˜„ì¬ ë…¸ë“œê°€ node_namesì— ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if not node_names or curr_node in node_names:
            # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
            if callback:
                callback({"node": curr_node, "content": chunk_msg.content})
            # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
            else:
                # ë…¸ë“œê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  ì¶œë ¥
                if curr_node != prev_node:
                    print("\n" + "=" * 50)
                    print(f"ğŸ”„ Node: \033[1;36m{curr_node}\033[0m ğŸ”„")
                    print("- " * 25)
                print(chunk_msg.content, end="", flush=True)

            prev_node = curr_node

def invoke_graph(
    graph: CompiledStateGraph,
    inputs: dict,
    config: RunnableConfig,
    node_names: List[str] = [],
    callback: Callable = None,
):
    """
    LangGraph ì•±ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì˜ˆì˜ê²Œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        graph (CompiledStateGraph): ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
        inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
        config (RunnableConfig): ì‹¤í–‰ ì„¤ì •
        node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        callback (Callable, optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
            ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": str} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.

    Returns:
        None: í•¨ìˆ˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ì¶œë ¥ë§Œ í•˜ê³  ë°˜í™˜ê°’ì€ ì—†ìŠµë‹ˆë‹¤.
    """

    def format_namespace(namespace):
        return namespace[-1].split(":")[0] if len(namespace) > 0 else "root graph"

    # subgraphs=True ë¥¼ í†µí•´ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ë„ í¬í•¨
    for namespace, chunk in graph.stream(
        inputs, config, stream_mode="updates", subgraphs=True
    ):
        for node_name, node_chunk in chunk.items():
            # node_namesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í•„í„°ë§
            if len(node_names) > 0 and node_name not in node_names:
                continue

            # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
            if callback is not None:
                callback({"node": node_name, "content": node_chunk})
            # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
            else:
                print("\n" + "=" * 50)
                formatted_namespace = format_namespace(namespace)
                if formatted_namespace == "root graph":
                    print(f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m ğŸ”„")
                else:
                    print(
                        f"ğŸ”„ Node: \033[1;36m{node_name}\033[0m in [\033[1;33m{formatted_namespace}\033[0m] ğŸ”„"
                    )
                print("- " * 25)

                # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥
                if isinstance(node_chunk, dict):
                    for k, v in node_chunk.items():
                        if isinstance(v, BaseMessage):
                            v.pretty_print()
                        elif isinstance(v, list):
                            for list_item in v:
                                if isinstance(list_item, BaseMessage):
                                    list_item.pretty_print()
                                else:
                                    print(list_item)
                        elif isinstance(v, dict):
                            for node_chunk_key, node_chunk_value in v.items():
                                print(f"{node_chunk_key}:\n{node_chunk_value}")
                        else:
                            print(f"\033[1;32m{k}\033[0m:\n{v}")
                else:
                    if node_chunk is not None:
                        for item in node_chunk:
                            print(item)
                print("=" * 50)

class PandasAgentStreamParser:
    """
    Pandas ì—ì´ì „íŠ¸ì˜ ìŠ¤íŠ¸ë¦¼ ì¶œë ¥ì„ íŒŒì‹±í•˜ê³  ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self, callbacks: AgentCallbacks = None):
        self.callbacks = callbacks or AgentCallbacks()
        self.output = None

    def process_agent_steps(self, step: Dict[str, Any]) -> None:
        """ì—ì´ì „íŠ¸ ìŠ¤í…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        if "actions" in step:
            self._process_actions(step["actions"])
        elif "steps" in step:
            self._process_observations(step["steps"])
        elif "output" in step:
            self._process_result(step["output"])
        elif "intermediate_steps" in step:
            self._process_intermediate_steps(step["intermediate_steps"])

    def _process_actions(self, actions: List[Any]) -> None:
        """ì•¡ì…˜ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        for action in actions:
            if isinstance(action, (AgentAction, ToolAgentAction)) and hasattr(action, "tool"):
                self._process_tool_call(action)

    def _process_tool_call(self, action: Any) -> None:
        """ë„êµ¬ í˜¸ì¶œì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        tool_action = {
            "tool": getattr(action, "tool", None),
            "tool_input": getattr(action, "tool_input", None),
            "log": getattr(action, "log", None),
        }
        self.callbacks.tool_callback(tool_action)

    def _process_observations(self, observations: List[Any]) -> None:
        """ê´€ì°° ê²°ê³¼ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        for observation in observations:
            observation_dict = {}
            if isinstance(observation, AgentStep):
                observation_dict["observation"] = getattr(observation, "observation", None)
            elif hasattr(observation, "observation"):
                observation_dict["observation"] = getattr(observation, "observation", None)
            else:
                observation_dict["observation"] = str(observation)
            self.callbacks.observation_callback(observation_dict)

    def _process_intermediate_steps(self, intermediate_steps: List[Any]) -> None:
        """ì¤‘ê°„ ìŠ¤í…ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        for step in intermediate_steps:
            if hasattr(step, "action") and hasattr(step, "observation"):
                # AgentStep í˜•íƒœ
                action = step.action
                observation = step.observation
                
                # ì•¡ì…˜ ì²˜ë¦¬
                if hasattr(action, "tool"):
                    tool_action = {
                        "tool": getattr(action, "tool", None),
                        "tool_input": getattr(action, "tool_input", None),
                        "log": getattr(action, "log", None),
                    }
                    self.callbacks.tool_callback(tool_action)
                
                # ê´€ì°° ì²˜ë¦¬
                observation_dict = {"observation": observation}
                self.callbacks.observation_callback(observation_dict)
            elif isinstance(step, tuple) and len(step) == 2:
                # (action, observation) íŠœí”Œ í˜•íƒœ
                action, observation = step
                
                # ì•¡ì…˜ ì²˜ë¦¬
                if hasattr(action, "tool"):
                    tool_action = {
                        "tool": getattr(action, "tool", None),
                        "tool_input": getattr(action, "tool_input", None),
                        "log": getattr(action, "log", None),
                    }
                    self.callbacks.tool_callback(tool_action)
                
                # ê´€ì°° ì²˜ë¦¬
                observation_dict = {"observation": observation}
                self.callbacks.observation_callback(observation_dict)

    def _process_result(self, result: str) -> None:
        """ìµœì¢… ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        self.callbacks.result_callback(result)
        self.output = result


def pandas_tool_callback(tool) -> None:
    """Pandas ì—ì´ì „íŠ¸ìš© ë„êµ¬ ì½œë°± í•¨ìˆ˜"""
    print("[ğŸ Python ì½”ë“œ ì‹¤í–‰]")
    print(f"Tool: {tool.get('tool')}")
    if tool_input := tool.get("tool_input"):
        for k, v in tool_input.items():
            if k == "query":
                print(f"ì½”ë“œ:\n{v}")
            else:
                print(f"{k}: {v}")
    if log := tool.get('log'):
        print(f"Log: {log}")


def pandas_observation_callback(observation) -> None:
    """Pandas ì—ì´ì „íŠ¸ìš© ê´€ì°° ì½œë°± í•¨ìˆ˜"""
    print("[ğŸ“Š ì‹¤í–‰ ê²°ê³¼]")
    if "observation" in observation:
        obs = observation["observation"]
        # ê²°ê³¼ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        if isinstance(obs, str) and len(obs) > 1000:
            obs = obs[:1000] + "..."
        print(f"ê²°ê³¼: {obs}")


def pandas_result_callback(result: str) -> None:
    """Pandas ì—ì´ì „íŠ¸ìš© ê²°ê³¼ ì½œë°± í•¨ìˆ˜"""
    print("[âœ… ìµœì¢… ë‹µë³€]")
    print(result)

def make_mcp_tool_sync_compatible(mcp_tool):
    """
    MCP ìª½ì—ì„œ ë„˜ê²¨ì˜¨ BaseTool / StructuredTool ì„
    â€¢ sync ì»¨í…ìŠ¤íŠ¸(pandas agent) ì—ì„œë„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
    â€¢ ë‹¨ì¼-ì¸í’‹ & ë‹¤ì¤‘-ì¸í’‹ ëª¨ë‘ ì²˜ë¦¬
    """

    # 1) ë‹¨ì¼-ì¸í’‹ íŒë³„ -------------------------------------------------
    def _is_single_input(tool):
        if getattr(tool, "args_schema", None):
            fields = list(tool.args_schema.__fields__)
            if len(fields) == 1:
                return True, fields[0]
        try:
            sig = inspect.signature(tool.func if hasattr(tool, "func") else tool)
            pos = [p.name for p in sig.parameters.values()
                   if p.kind in (p.POSITIONAL_ONLY, p.POSITIONAL_OR_KEYWORD)]
            if len(pos) == 1:
                return True, pos[0]
        except Exception:
            pass
        return False, None

    single_input, single_key = _is_single_input(mcp_tool)

    # 2) ì‹¤ì œ ì‹¤í–‰ í•¨ìˆ˜ -------------------------------------------------
    def _prep_args(tool_input):
        """
        â€¢ ë‹¨ì¼-ì¸í’‹  â†’ str ë¡œ ë³€í™˜í•˜ê±°ë‚˜ key ë§¤ì¹­
        â€¢ ë‹¤ì¤‘-ì¸í’‹  â†’ dict ê·¸ëŒ€ë¡œ
        """
        if single_input:
            if isinstance(tool_input, dict):
                if single_key and single_key in tool_input:
                    return tool_input[single_key]
                return json.dumps(tool_input, ensure_ascii=False)
            return tool_input          # ì´ë¯¸ str
        else:
            return tool_input if isinstance(tool_input, dict) else {"input": tool_input}

    def sync_runner(*args, **kwargs):
        raw_in        = args[0] if (len(args) == 1 and not kwargs) else (kwargs or {})
        fixed_in      = _prep_args(raw_in)

        try:
            # â‘  StructuredTool ì€ .invoke() ì‚¬ìš©  (sync ì§€ì›)
            if isinstance(mcp_tool, StructuredTool):
                return mcp_tool.invoke(fixed_in)

            # â‘¡ ì¼ë°˜ Tool  -------------------------------
            #    run() ì€ ë¬¸ìì—´(ë‹¨ì¼-ì¸í’‹)ë§Œ, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ invoke()
            if single_input and not isinstance(fixed_in, dict):
                return mcp_tool.run(fixed_in)
            return mcp_tool.invoke(fixed_in)

        except Exception as e:
            # [ERROR] í”„ë¦¬í”½ìŠ¤ â†’ LLM ì´ ì¬ì‹œë„ ë°©ë²• ë°”ê¾¸ë„ë¡ ìœ ë„
            return f"[ERROR] {e}"

    # 3) ë¹„ë™ê¸°ìš© thin wrapper -----------------------------------------
    async def async_runner(*args, **kwargs):
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(
            _fut.ThreadPoolExecutor(max_workers=1),
            lambda: sync_runner(*args, **kwargs)
        )

    mcp_tool.run_sync   = sync_runner      # pandas agent ì—ì„œ ì‚¬ìš©
    mcp_tool.ainvoke    = async_runner     # LangGraph ìš© ëŒ€ë¹„
    return mcp_tool

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MCP ë¹„ë™ê¸° Tool â†’ pandas-agent í˜¸í™˜ Tool (sync & async ì§€ì›) ë˜í¼
#   - StructuredTool ë¡œ ì¬ë˜í•‘ë˜ì§€ ì•Šë„ë¡ Tool í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ë°˜í™˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_sync_tool(mcp_tool):
    """
    ì£¼ì–´ì§„ MCP ë¹„ë™ê¸° ë„êµ¬ë¥¼ pandas-agent ê°€ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ”
    langchain_core.tools.Tool ë¡œ ê°ì‹¸ ë°˜í™˜í•œë‹¤.
    """
    name        = getattr(mcp_tool, "name", "mcp_tool")
    description = getattr(mcp_tool, "description", f"{name} (sync-wrapper)")

    # â”€â”€ ë™ê¸° ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _sync_runner(query_or_dict):
        """
        pandas-agent ê°€ ë„˜ê²¨ì£¼ëŠ” ë¬¸ìì—´ Â· dict ì¸í’‹ì„
        MCP ë„êµ¬ê°€ ìš”êµ¬í•˜ëŠ” **dict í˜•íƒœ**ë¡œ ë³€í™˜í•œ ë’¤ ì‹¤í–‰
        """
        # â‘  ì´ë¯¸ dict ë¡œ ì™”ë‹¤ë©´ ê·¸ëŒ€ë¡œ
        if isinstance(query_or_dict, dict):
            input_dict = query_or_dict
        else:
            # â‘¡ ë¬¸ìì—´ âœ dict ë¡œ ë³€í™˜
            input_str = str(query_or_dict)

            # args_schema ê°€ ìˆìœ¼ë©´ í•„ìˆ˜ í•„ë“œëª… ì¶”ì¶œ (ëŒ€ê°œ "__arg1" í•˜ë‚˜)
            if getattr(mcp_tool, "args_schema", None):
                fields = list(getattr(mcp_tool.args_schema, "__fields__", {}).keys())
                key = fields[0] if fields else "query"
            else:
                key = "query"

            input_dict = {key: input_str}

        try:
            # StructuredTool â†’ invoke ì‚¬ìš©ì´ ì•ˆì „
            if isinstance(mcp_tool, StructuredTool) or hasattr(mcp_tool, "invoke"):
                return mcp_tool.invoke(input_dict)
            # ì¼ë°˜ callable(BaseTool) â†’ ê·¸ëƒ¥ í˜¸ì¶œ
            return mcp_tool(input_dict)
        except Exception as e:
            logging.error(f"[{name}] sync ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return f"Error: {e}"

    # â”€â”€ ë¹„ë™ê¸° ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def _async_runner(query_or_dict):
        # ë™ì¼ dict ë³€í™˜ ë¡œì§ ì¬ì‚¬ìš©
        if isinstance(query_or_dict, dict):
            input_dict = query_or_dict
        else:
            input_dict = {"query": str(query_or_dict)}

        # ìš°ì„  ë¹„ë™ê¸° ë©”ì„œë“œê°€ ìˆë‚˜ í™•ì¸
        for meth in ("ainvoke", "arun", "acall"):
            fn = getattr(mcp_tool, meth, None)
            if callable(fn):
                return await fn(input_dict)

        # ì—†ìœ¼ë©´ ìŠ¤ë ˆë“œí’€ì—ì„œ sync í˜¸ì¶œ
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, _sync_runner, input_dict)

    return Tool(
        name         = name,
        description  = description,
        func         = _sync_runner,
        async_func   = _async_runner,
        # ğŸ”‘  JSON-schema ìë™ ì¶”ë¡  ë„ê¸° â†’ ë¬¸ìì—´ ì¸í’‹ í—ˆìš©
        args_schema  = None,
        infer_schema = False,
    )