import streamlit as st
import glob
import json
import os
from pathlib import Path
from copy import deepcopy
from dotenv import load_dotenv, find_dotenv
import asyncio
import nest_asyncio
import platform
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage, AIMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig
import requests
import sys
from contextlib import asynccontextmanager
from mcp.client import stdio as _stdio
import logging
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import BaseMessage
from langchain_core.outputs import ChatResult, ChatGeneration
from pydantic import ConfigDict
import yaml
from langchain_openai import ChatOpenAI
from urllib.parse import urlsplit, parse_qs
from utils import generate_followups, get_followup_llm

# Base directory for app icons
ASSETS_DIR = "assets"
URL_BASE = "http://localhost:2025/Agent?id="

# Configure logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# Log session state initialization
logging.debug('Initializing session state')

if platform.system() == "Windows":
    logging.debug(f"Using proactor: IocpProactor")
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# nest_asyncio ì ìš©: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ì—ì„œ ì¤‘ì²© í˜¸ì¶œ í—ˆìš©
nest_asyncio.apply()

# ì „ì—­ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì¬ì‚¬ìš© (í•œë²ˆ ìƒì„±í•œ í›„ ê³„ì† ì‚¬ìš©)
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)


st.set_page_config(
    page_title="AI Agent Builder",
    layout="wide",
    initial_sidebar_state="expanded",
)


OUTPUT_TOKEN_INFO = {
    "o4-mini": {"max_tokens": 16000},
    "gpt-4o": {"max_tokens": 16000},
}

# Log function entry and exit
logging.debug('Entering function: initialize_session')
async def initialize_session(mcp_config=None):
    logging.debug('Initializing MCP session')
    with st.spinner("ğŸ”„ MCP ì„œë²„ì— ì—°ê²° ì¤‘..."):
        await cleanup_mcp_client()
        logging.debug('MCP client cleaned up')

        # mcp_configì´ Noneì´ê±°ë‚˜ tool_configê°€ ì—†ëŠ” ê²½ìš° MCP ì—°ê²°ì„ ê±´ë„ˆëœë‹ˆë‹¤.
        if mcp_config is None and (
            "tool_config" not in st.session_state or st.session_state.tool_config is None
        ):
            st.warning("âš ï¸ MCP ì„œë²„ ì—°ê²°ì„ ê±´ë„ˆëœë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ MCP Toolì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.session_state.tool_count = 0
            st.session_state.mcp_client = None
            st.session_state.session_initialized = True
            logging.debug('No tool configuration found, skipping MCP connection.')
            return True

        # mcp_configì´ Noneì´ë©´ ì‚¬ì´ë“œë°”ì—ì„œ ë¡œë“œëœ tool_config ì‚¬ìš©
        if mcp_config is None:
            mcp_config = st.session_state.tool_config

        # mcpServers í‚¤ê°€ ìˆìœ¼ë©´ í•´ì œ
        connections = mcp_config.get("mcpServers", mcp_config)
        
        # Store connections for debugging
        st.session_state.last_mcp_connections = connections
        logging.debug(f"MCP connections configuration: {json.dumps(connections, indent=2)}")
        
        # MCP ì„œë²„ ì„¤ì •ì´ ë¹„ì–´ ìˆìœ¼ë©´ ê±´ë„ˆëœë‹ˆë‹¤.
        if not connections:
            st.warning("âš ï¸ MCP ì„œë²„ ì„¤ì •ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. MCP ì—°ê²°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            st.session_state.tool_count = 0
            st.session_state.mcp_client = None
            st.session_state.session_initialized = True
            logging.debug('MCP server configuration is empty, skipping connection.')
            return True

        # Initialize MCP client and connect to servers
        try:
            logging.debug("Creating MultiServerMCPClient with connections")
            client = MultiServerMCPClient(connections)
            
            logging.debug("Entering MCP client context")
            await client.__aenter__()
            logging.debug('MCP servers connected via context manager.')
            
            try:
                # Get and log available tools
                logging.debug("Retrieving tools from MCP client")
                tools = client.get_tools()
                tool_count = len(tools)
                st.session_state.tool_count = tool_count
                
                # Log individual tool details
                logging.debug(f"Retrieved {tool_count} tools from MCP client")
                for i, tool in enumerate(tools):
                    tool_name = getattr(tool, 'name', f"Tool_{i}")
                    logging.debug(f"Tool {i}: {tool_name}")
                    if hasattr(tool, 'args'):
                        logging.debug(f"Tool {i} args: {tool.args}")
                    if hasattr(tool, 'description'):
                        logging.debug(f"Tool {i} description: {tool.description}")
                
                st.session_state.mcp_client = client
            except Exception as e:
                logging.error(f"Error retrieving tools: {str(e)}")
                import traceback
                logging.error(f"Tool retrieval error details:\n{traceback.format_exc()}")
                st.error(f"MCP ë„êµ¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                # Continue with empty tools list
                tools = []
                tool_count = 0
                st.session_state.tool_count = 0
            
            # Create React agent graph if tools are available
            if tool_count > 0:
                # Replace HTTPChatModel usage with ChatOpenAI
                load_dotenv()
                # Construct OpenAI API base URL (always host + /v1)
                raw_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com")
                # Remove any path, keep only scheme and netloc
                parsed = urlsplit(raw_base)
                openai_api_base = f"{parsed.scheme}://{parsed.netloc}/v1"
                openai_api_key = os.getenv("OPENAI_API_KEY", "")
                logging.debug(f"Creating ChatOpenAI with base_url: {openai_api_base}")
                model = ChatOpenAI(
                    model=st.session_state.selected_model,
                    temperature=st.session_state.temperature,
                    max_tokens=OUTPUT_TOKEN_INFO[st.session_state.selected_model]["max_tokens"],
                    api_key=openai_api_key,
                    base_url=openai_api_base,
                )
                try:
                    agent = create_react_agent(
                        model,
                        tools,
                        prompt=st.session_state.selected_prompt_text,
                        checkpointer=MemorySaver(),
                    )
                    st.session_state.agent = agent
                except Exception as e:
                    logging.error(f"Error creating ReAct agent: {str(e)}")
                    import traceback
                    logging.error(f"Agent creation error details:\n{traceback.format_exc()}")
                    st.error(f"ì—ì´ì „íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.session_state.agent = None
                logging.debug('React agent creation complete')
            else:
                st.session_state.agent = None
                logging.warning('No tools available, React agent not created.')
            
            st.session_state.session_initialized = True
            return True
            
        except Exception as e:
            import traceback
            error_msg = f"Error initializing MCP client: {str(e)}"
            logging.error(f"{error_msg}\n{traceback.format_exc()}")
            st.error(error_msg)
            st.session_state.session_initialized = False
            return False

# Log function entry and exit
logging.debug('Entering function: cleanup_mcp_client')
async def cleanup_mcp_client():
    """
    ê¸°ì¡´ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.

    ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì •ìƒì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤.
    """
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:
            await st.session_state.mcp_client.__aexit__(None, None, None)
            st.session_state.mcp_client = None
        except Exception as e:
            import traceback
            logging.error(f"MCP client cleanup error: {str(e)}\n{traceback.format_exc()}")
    logging.debug('Exiting function: cleanup_mcp_client')


def print_message():
    """
    ì±„íŒ… ê¸°ë¡ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìì™€ ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•˜ê³ ,
    ë„êµ¬ í˜¸ì¶œ ì •ë³´ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ë‚´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    """
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]

        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘ğŸ»").write(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ë‚´ìš© í‘œì‹œ
                st.write(message["content"])

                # --- Followup ë²„íŠ¼ ë Œë”ë§ ---
                followups = message.get("followups")
                if followups:
                    st.markdown("<div style='margin-top: 0.5em; margin-bottom: 0.5em; color: #888;'>í›„ì† ì§ˆë¬¸ ì œì•ˆ:</div>", unsafe_allow_html=True)
                    btn_cols = st.columns(len(followups))
                    for idx, followup in enumerate(followups):
                        if btn_cols[idx].button(followup, key=f"followup_{i}_{idx}"):
                            st.session_state["user_query"] = followup
                            st.rerun()

                # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ì¸ì§€ í™•ì¸
                if (
                    i + 1 < len(st.session_state.history)
                    and st.session_state.history[i + 1]["role"] == "assistant_tool"
                ):
                    # ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ë™ì¼í•œ ì»¨í…Œì´ë„ˆ ë‚´ì— expanderë¡œ í‘œì‹œ
                    with st.expander("ğŸ”§ ë„êµ¬ í˜¸ì¶œ ì •ë³´", expanded=False):
                        st.write(st.session_state.history[i + 1]["content"])
                    i += 2  # ë‘ ë©”ì‹œì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 2 ì¦ê°€
                else:
                    i += 1  # ì¼ë°˜ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ 1 ì¦ê°€
        else:
            # assistant_tool ë©”ì‹œì§€ëŠ” ìœ„ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ê±´ë„ˆëœ€
            i += 1


def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” LLMì—ì„œ ìƒì„±ë˜ëŠ” ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ê°ê° ë‹¤ë¥¸ ì˜ì—­ì— í‘œì‹œí•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸

    ë°˜í™˜ê°’:
        callback_func: ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¨ìˆ˜
        accumulated_text: ëˆ„ì ëœ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
        accumulated_tool: ëˆ„ì ëœ ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    """
    accumulated_text = []
    accumulated_tool = []
    # Track tool call IDs to prevent duplicate pending calls
    seen_tool_call_ids = set()

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        logging.debug(f"Streaming callback received message: {type(message)}")
        message_content = message.get("content", None)
        
        # Log message content for debugging
        if message_content:
            logging.debug(f"Message content type: {type(message_content)}")
            if hasattr(message_content, "content"):
                content_sample = str(message_content.content)[:100] + "..." if len(str(message_content.content)) > 100 else str(message_content.content)
                logging.debug(f"Content: {content_sample}")
        else:
            logging.debug("No message content found")
            
        # Handle complete AIMessage (non-chunked)
        if isinstance(message_content, AIMessage):
            logging.debug("Processing complete AIMessage")
            content = message_content.content
            if isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.write("".join(accumulated_text))
                logging.debug(f"Added complete AIMessage content to text: {content[:100]}...")
            
            # Check for tool calls in additional_kwargs
            if hasattr(message_content, "additional_kwargs") and "tool_calls" in message_content.additional_kwargs and message_content.additional_kwargs["tool_calls"]:
                tool_calls = message_content.additional_kwargs["tool_calls"]
                logging.debug("Found tool_calls in AIMessage additional_kwargs")
                for tool_call in tool_calls:
                    tool_id = tool_call.get("id")
                    tool_name = tool_call.get("function", {}).get("name", "")
                    raw_arguments = tool_call.get("function", {}).get("arguments", None)
                    if isinstance(raw_arguments, str):
                        try:
                            args = json.loads(raw_arguments)
                        except:
                            args = {"raw_arguments": raw_arguments}
                    else:
                        args = raw_arguments
                    # Accumulate formatted tool call info
                    call_info = {"name": tool_name, "args": args, "id": tool_id, "type": "tool_call"}
                    # Display only raw_arguments when available
                    if raw_arguments is not None:
                        if isinstance(raw_arguments, str):
                            raw_display = raw_arguments
                        else:
                            raw_display = json.dumps(raw_arguments, indent=2, ensure_ascii=False)
                        if tool_name:
                            if tool_name=='execute_python':
                                entry = f"\n**ë„êµ¬ í˜¸ì¶œ: {tool_name}**\n\n{raw_display}\n"
                            else:
                                entry = f"\n**ë„êµ¬ í˜¸ì¶œ: {tool_name}**\n\n{raw_display}\n"
                        else:
                            entry = raw_display
                            # entry = raw_display.replace("\n", "")
                        accumulated_tool.append(entry)
                    # Store tool call for later processing (only once per call)
                    if tool_id and tool_name and tool_id not in seen_tool_call_ids:
                        seen_tool_call_ids.add(tool_id)
                        if "pending_tool_calls" not in st.session_state:
                            st.session_state.pending_tool_calls = []
                        st.session_state.pending_tool_calls.append({
                            "id": tool_id,
                            "name": tool_name,
                            "arguments": args
                        })
                        logging.debug(f"Added pending tool call: {tool_name} (id: {tool_id})")
                tool_placeholder.write("".join(accumulated_tool))
            
            return None

        # Handle AIMessageChunk
        if isinstance(message_content, AIMessageChunk):
            logging.debug("Processing AIMessageChunk")
            content = message_content.content
            
            # Content is list (e.g., Claude format)
            if isinstance(content, list) and len(content) > 0:
                logging.debug(f"AIMessageChunk content is list of length {len(content)}")
                message_chunk = content[0]
                if message_chunk.get("type") == "text":
                    text = message_chunk.get("text", "")
                    accumulated_text.append(text)
                    text_placeholder.write("".join(accumulated_text))
                    logging.debug(f"Added text chunk: {text[:100]}...")
                elif message_chunk.get("type") == "tool_use":
                    logging.debug("Processing tool_use chunk")
                    # Handle partial JSON fragments if available
                    if "partial_json" in message_chunk:
                        partial = message_chunk["partial_json"]
                        try:
                            pretty = json.dumps(json.loads(partial), indent=2, ensure_ascii=False)
                        except Exception:
                            pretty = partial
                        entry = f"\n```json\n{pretty}\n```\n"
                    else:
                        # Fallback to full tool_call_chunks
                        chunks = getattr(message_content, "tool_call_chunks", None)
                        if chunks:
                            chunk = chunks[0]
                            entry = f"\n```json\n{str(chunk)}\n```\n"
                        else:
                            entry = ""
                    accumulated_tool.append(entry)
                    tool_placeholder.write("".join(accumulated_tool))
                # Skip non-text, non-tool_use chunks
            # Check for OpenAI style tool calls
            elif (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls) > 0
            ):
                logging.debug("Found tool_calls attribute in AIMessageChunk")
                tool_call_info = message_content.tool_calls[0]
                tool_id = tool_call_info.get("id")
                tool_name = tool_call_info.get("function", {}).get("name", "")
                raw_arguments = tool_call_info.get("function", {}).get("arguments", None)
                if isinstance(raw_arguments, str):
                    try:
                        args = json.loads(raw_arguments)
                    except:
                        args = {"raw_arguments": raw_arguments}
                else:
                    args = raw_arguments
                call_info = {"name": tool_name, "args": args, "id": tool_id, "type": "tool_call"}
                # Display only raw_arguments when available
                if raw_arguments is not None:
                    if isinstance(raw_arguments, str):
                        raw_display = raw_arguments
                    else:
                        raw_display = json.dumps(raw_arguments, indent=2, ensure_ascii=False)
                    entry = raw_display
                    accumulated_tool.append(entry)
                # Store tool call for later processing
                if tool_id and tool_name and tool_id not in seen_tool_call_ids:
                    seen_tool_call_ids.add(tool_id)
                    if "pending_tool_calls" not in st.session_state:
                        st.session_state.pending_tool_calls = []
                    st.session_state.pending_tool_calls.append({
                        "id": tool_id,
                        "name": tool_name,
                        "arguments": args
                    })
                    logging.debug(f"Added pending tool call from chunk: {tool_name} (id: {tool_id})")
                tool_placeholder.write("".join(accumulated_tool))
            
            # Simple string content
            elif isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.write("".join(accumulated_text))
                logging.debug(f"Added string content: {content[:100]}...")
            
            # Invalid tool calls
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                logging.debug("Found invalid_tool_calls in AIMessageChunk")
                tool_call_info = message_content.invalid_tool_calls[0]
                tool_str = json.dumps(tool_call_info, indent=2)
                entry = tool_str.replace("\n", "")
                accumulated_tool.append(entry)
                tool_placeholder.write("".join(accumulated_tool))
                logging.debug(f"Added invalid tool call info: {tool_str[:100]}...")
            
            # Tool call chunks
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                logging.debug("Found tool_call_chunks in AIMessageChunk")
                tool_call_chunk = message_content.tool_call_chunks[0]
                tool_str = str(tool_call_chunk)
                # entry = tool_str.replace("\n", "")
                accumulated_tool.append(entry)
                tool_placeholder.write("".join(accumulated_tool))
                logging.debug(f"Added tool call chunk: {tool_str[:100]}...")
            
            # Additional kwargs with tool calls
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
                and message_content.additional_kwargs["tool_calls"]
            ):
                logging.debug("Found tool_calls in additional_kwargs")
                tool_calls = message_content.additional_kwargs["tool_calls"]
                for tool_call in tool_calls:
                    tool_id = tool_call.get("id")
                    tool_name = tool_call.get("function", {}).get("name", "")
                    raw_arguments = tool_call.get("function", {}).get("arguments", None)
                    if isinstance(raw_arguments, str):
                        try:
                            args = json.loads(raw_arguments)
                        except:
                            args = {"raw_arguments": raw_arguments}
                    else:
                        args = raw_arguments
                    call_info = {"name": tool_name, "args": args, "id": tool_id, "type": "tool_call"}
                    # Display only raw_arguments when available
                    if raw_arguments is not None:
                        if isinstance(raw_arguments, str):
                            raw_display = raw_arguments
                        else:
                            raw_display = json.dumps(raw_arguments, indent=2, ensure_ascii=False)
                        if tool_name:
                            entry = f"\n**ë„êµ¬ í˜¸ì¶œ: {tool_name}**\n{raw_display}\n"
                        # else:
                        #     entry = raw_display.replace("\n", "")
                        accumulated_tool.append(entry)
                    if tool_id and tool_name and tool_id not in seen_tool_call_ids:
                        seen_tool_call_ids.add(tool_id)
                        if "pending_tool_calls" not in st.session_state:
                            st.session_state.pending_tool_calls = []
                        st.session_state.pending_tool_calls.append({
                            "id": tool_id,
                            "name": tool_name,
                            "arguments": args
                        })
                        logging.debug(f"Added pending tool call from kwargs: {tool_name} (id: {tool_id})")
                tool_placeholder.write("".join(accumulated_tool))
            
            else:
                logging.warning(f"Unhandled AIMessageChunk content format: {type(content)}")
        
        # Handle ToolMessage - this is the tool response
        elif isinstance(message_content, ToolMessage):
            logging.debug("Processing ToolMessage")
            tool_name = getattr(message_content, "name", "unknown_tool")
            tool_call_id = getattr(message_content, "tool_call_id", "unknown_id")
            content_str = str(message_content.content)
            
            logging.debug(f"ToolMessage received: name={tool_name}, tool_call_id={tool_call_id}")
            logging.debug(f"ToolMessage content: {content_str[:200]}...")
            
            # Store tool response for later processing
            if "tool_responses" not in st.session_state:
                st.session_state.tool_responses = {}
                
            st.session_state.tool_responses[tool_call_id] = {
                "name": tool_name,
                "content": content_str
            }
            
            # Find and remove from pending tools
            if "pending_tool_calls" in st.session_state:
                st.session_state.pending_tool_calls = [
                    call for call in st.session_state.pending_tool_calls 
                    if call.get("id") != tool_call_id
                ]
            
            # Add tool response JSON to the displayed tools
            try:
                response_data = json.loads(content_str)
                formatted = json.dumps(response_data, indent=2)
            except:
                formatted = content_str
            
            entry = f"\n\n**ë„êµ¬ í˜¸ì¶œ ê²°ê³¼: {tool_name}**\n\n{formatted}\n"
            
            accumulated_tool.append(entry)
            tool_placeholder.write("".join(accumulated_tool))
            logging.debug(f"Added tool response content: {formatted[:100]}...")
        
        else:
            logging.warning(f"Unhandled message content type: {type(message_content)}")
        
        return None

    return callback_func, accumulated_text, accumulated_tool


# Handle tool execution
async def execute_tool(tool_call, tools):
    """Execute a tool and return its response"""
    tool_id = tool_call.get("id")
    tool_name = tool_call.get("name")
    arguments = tool_call.get("arguments", {})
    
    logging.debug(f"Executing tool: {tool_name} (ID: {tool_id})")
    logging.debug(f"Arguments: {arguments}")
    
    # Find the matching tool
    matching_tool = None
    for tool in tools:
        if getattr(tool, "name", "") == tool_name:
            matching_tool = tool
            break
    
    if not matching_tool:
        error_msg = f"Tool {tool_name} not found"
        logging.error(error_msg)
        return {
            "tool_call_id": tool_id,
            "name": tool_name,
            "content": f"Error: {error_msg}"
        }
    
    try:
        # Execute the tool with provided arguments
        result = await matching_tool.ainvoke(arguments)
        logging.debug(f"Tool execution result: {str(result)[:200]}...")
        
        # Create response
        return {
            "tool_call_id": tool_id,
            "name": tool_name,
            "content": str(result)
        }
    except Exception as e:
        import traceback
        error_msg = f"Error executing tool {tool_name}: {str(e)}"
        error_trace = traceback.format_exc()
        logging.error(f"{error_msg}\n{error_trace}")
        return {
            "tool_call_id": tool_id,
            "name": tool_name,
            "content": f"Error: {error_msg}"
        }


# Log function entry and exit
logging.debug('Entering function: process_query')
async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì—ì´ì „íŠ¸ì— ì „ë‹¬í•˜ê³ , ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.
    ì§€ì •ëœ ì‹œê°„ ë‚´ì— ì‘ë‹µì´ ì™„ë£Œë˜ì§€ ì•Šìœ¼ë©´ íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        query: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ í…ìŠ¤íŠ¸
        text_placeholder: í…ìŠ¤íŠ¸ ì‘ë‹µì„ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        tool_placeholder: ë„êµ¬ í˜¸ì¶œ ì •ë³´ë¥¼ í‘œì‹œí•  Streamlit ì»´í¬ë„ŒíŠ¸
        timeout_seconds: ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)

    ë°˜í™˜ê°’:
        response: ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ê°ì²´
        final_text: ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ
        final_tool: ìµœì¢… ë„êµ¬ í˜¸ì¶œ ì •ë³´
    """
    try:
        if st.session_state.agent:
            logging.debug(f"Processing query: {query}")
            streaming_callback, accumulated_text_obj, accumulated_tool_obj = (
                get_streaming_callback(text_placeholder, tool_placeholder)
            )
            
            # Reset tool tracking for new query
            st.session_state.pending_tool_calls = []
            st.session_state.tool_responses = {}
            
            try:
                # Log agent type and tools before processing
                logging.debug(f"Agent type: {type(st.session_state.agent)}")
                
                # Create runnable config with additional diagnostics
                config = RunnableConfig(
                    recursion_limit=st.session_state.recursion_limit,
                    thread_id=st.session_state.thread_id,
                    configurable={
                        "callbacks": [
                            # Add a simple callback for additional logging
                            lambda x: logging.debug(f"RunnableConfig callback: {str(x)[:100]}...")
                        ]
                    }
                )
                
                logging.debug(f"Starting agent execution with timeout: {timeout_seconds}s")
                
                # Start the agent execution
                agent_task = astream_graph(
                    st.session_state.agent,
                    {"messages": [HumanMessage(content=query)]},
                    callback=streaming_callback,
                    config=config,
                )
                
                # Process tool calls and agent responses
                has_tool_calls = False
                response = None
                
                # Use a timeout to prevent hanging
                try:
                    start_time = asyncio.get_event_loop().time()
                    remaining_time = timeout_seconds
                    
                    # Wait for initial response
                    response = await asyncio.wait_for(
                        agent_task,
                        timeout=remaining_time
                    )
                    
                    # Check for tool calls
                    logging.debug("Initial agent response received")
                    if "pending_tool_calls" in st.session_state and st.session_state.pending_tool_calls:
                        has_tool_calls = True
                        
                        # Process each pending tool call
                        while st.session_state.pending_tool_calls and remaining_time > 0:
                            logging.debug(f"Processing pending tool calls: {len(st.session_state.pending_tool_calls)}")
                            
                            # Get next tool call
                            tool_call = st.session_state.pending_tool_calls[0]
                            logging.debug(f"Processing tool call: {tool_call}")
                            
                            # Update remaining time
                            current_time = asyncio.get_event_loop().time()
                            elapsed = current_time - start_time
                            remaining_time = timeout_seconds - elapsed
                            
                            # Execute tool with timeout
                            if remaining_time <= 0:
                                logging.warning("Tool execution timeout")
                                break
                                
                            tool_result = await asyncio.wait_for(
                                execute_tool(tool_call, st.session_state.mcp_client.get_tools()),
                                timeout=remaining_time
                            )
                            
                            # Create tool message
                            logging.debug(f"Tool result: {str(tool_result)[:200]}...")
                            tool_message = ToolMessage(
                                content=tool_result["content"],
                                name=tool_result["name"],
                                tool_call_id=tool_result["tool_call_id"]
                            )
                            
                            # Display tool result
                            with tool_placeholder.expander("ğŸ”§ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼", expanded=True):
                                st.write(f"**ë„êµ¬**: {tool_result['name']}\n\n**ê²°ê³¼**:\n```\n{tool_result['content'][:1000]}...\n```")
                            
                            # Update remaining time
                            current_time = asyncio.get_event_loop().time()
                            elapsed = current_time - start_time
                            remaining_time = timeout_seconds - elapsed
                            
                            # Pass tool result back to agent
                            if remaining_time <= 0:
                                logging.warning("Agent continuation timeout")
                                break
                                
                            agent_continue_task = astream_graph(
                                st.session_state.agent,
                                {"messages": [tool_message]},
                                callback=streaming_callback,
                                config=config,
                            )
                            
                            # Wait for agent response
                            response = await asyncio.wait_for(
                                agent_continue_task,
                                timeout=remaining_time
                            )
                            
                            # Remove processed tool call
                            st.session_state.pending_tool_calls = st.session_state.pending_tool_calls[1:]
                            
                            # Update remaining time
                            current_time = asyncio.get_event_loop().time()
                            elapsed = current_time - start_time
                            remaining_time = timeout_seconds - elapsed
                            
                            # Break if no more pending calls
                            if not st.session_state.pending_tool_calls:
                                logging.debug("No more pending tool calls")
                                break
                    
                except asyncio.TimeoutError:
                    error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                    logging.error(f"Query timed out after {timeout_seconds} seconds")
                    return {"error": error_msg}, error_msg, ""
                
                logging.debug("Query completed successfully")
                
                # Log response details
                if hasattr(response, 'get'):
                    resp_content = response.get('content', 'No content')
                    logging.debug(f"Response content: {str(resp_content)[:100]}...")
                else:
                    logging.debug(f"Response type: {type(response)}")
                
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                logging.error(f"Query timed out after {timeout_seconds} seconds")
                return {"error": error_msg}, error_msg, ""
            except Exception as e:
                import traceback
                error_msg = f"ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                error_trace = traceback.format_exc()
                logging.error(f"{error_msg}\n{error_trace}")
                return {"error": error_msg}, error_msg, error_trace

            # Process final results
            final_text = "".join(accumulated_text_obj)
            final_tool = "".join(accumulated_tool_obj)
            
            # Log final output for debugging
            logging.debug(f"Final text length: {len(final_text)}")
            logging.debug(f"Final text: {final_text[:100]}...")
            logging.debug(f"Final tool content length: {len(final_tool)}")
            logging.debug(f"Final tool content: {final_tool[:100]}...")
            
            return response, final_text, final_tool
        else:
            logging.warning("Agent not initialized before query")
            return (
                {"error": "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                "ğŸš« ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "",
            )
    except Exception as e:
        import traceback
        error_msg = f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        error_trace = traceback.format_exc()
        logging.error(f"{error_msg}\n{error_trace}")
        return {"error": error_msg}, error_msg, error_trace





def load_selected_prompt():
    selected = st.session_state["prompt_selectbox"]
    prompts_dict = prompt_data.get("prompts", {})
    if selected in prompts_dict:
        st.session_state.selected_prompt_name = selected
        st.session_state.selected_prompt_text = prompts_dict[selected]["prompt"]
        st.session_state.prompt_loaded = True
        st.session_state["sidebar_edit_prompt_text"] = prompts_dict[selected]["prompt"]


def load_selected_tool():
    selected = st.session_state["tool_selectbox"]
    logging.debug(f"Selected tool: {selected}")
    selected_tool = next((t for t in tools_list if t["name"] == selected), None)
    if selected_tool:
        logging.debug(f"Loading tool configuration from: {selected_tool['path']}")
        try:
            with open(selected_tool["path"], encoding="utf-8") as f:
                st.session_state.tool_config = json.load(f)
            st.session_state.file_path = selected_tool["path"]
            st.session_state.loaded = True
            # Normalize pending MCP config: only keep valid connection fields
            raw_conf = st.session_state.tool_config.get("mcpServers", st.session_state.tool_config)
            pending_conf = {}
            for srv_name, srv_cfg in raw_conf.items():
                if "url" in srv_cfg:
                    # SSE connection
                    conf = {"transport": srv_cfg.get("transport", "sse"), "url": srv_cfg["url"]}
                    if "headers" in srv_cfg:
                        conf["headers"] = srv_cfg["headers"]
                    if "timeout" in srv_cfg:
                        conf["timeout"] = srv_cfg["timeout"]
                    if "sse_read_timeout" in srv_cfg:
                        conf["sse_read_timeout"] = srv_cfg["sse_read_timeout"]
                    if "session_kwargs" in srv_cfg:
                        conf["session_kwargs"] = srv_cfg["session_kwargs"]
                else:
                    # stdio connection
                    conf = {"transport": srv_cfg.get("transport", "stdio"), "command": srv_cfg["command"], "args": srv_cfg["args"]}
                    if "env" in srv_cfg:
                        conf["env"] = srv_cfg["env"]
                    if "cwd" in srv_cfg:
                        conf["cwd"] = srv_cfg["cwd"]
                    if "encoding" in srv_cfg:
                        conf["encoding"] = srv_cfg["encoding"]
                    if "encoding_error_handler" in srv_cfg:
                        conf["encoding_error_handler"] = srv_cfg["encoding_error_handler"]
                    if "session_kwargs" in srv_cfg:
                        conf["session_kwargs"] = srv_cfg["session_kwargs"]
                pending_conf[srv_name] = conf
            # Store direct mapping for initialization (initialize_session will unpack it)
            st.session_state.pending_mcp_config = pending_conf
            logging.debug("Tool configuration loaded successfully.")
        except Exception as e:
            logging.error(f"Error loading tool configuration: {str(e)}")




# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "session_initialized" not in st.session_state:
    logging.debug('Session state not initialized, setting default values')
    st.session_state.session_initialized = False  # ì„¸ì…˜ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸
    st.session_state.agent = None  # ReAct ì—ì´ì „íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.history = []  # ëŒ€í™” ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.session_state.mcp_client = None  # MCP í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ì €ì¥ ê³µê°„
    st.session_state.timeout_seconds = 180  # ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ), ê¸°ë³¸ê°’ 120ì´ˆ
    st.session_state.selected_model = "gpt-4o"  # ê¸°ë³¸ ëª¨ë¸ ì„ íƒ
    st.session_state.recursion_limit = 100  # ì¬ê·€ í˜¸ì¶œ ì œí•œ, ê¸°ë³¸ê°’ 100
    st.session_state.selected_prompt_text = ""  # initialize selected prompt text
    st.session_state.temperature = 0.1  # ê¸°ë³¸ temperature ì„¤ì •
    st.session_state.pending_tool_calls = []  # ëŒ€ê¸° ì¤‘ì¸ ë„êµ¬ í˜¸ì¶œ ëª©ë¡
    st.session_state.tool_responses = {}  # ë„êµ¬ ì‘ë‹µ ì €ì¥ ê³µê°„
    # Load default system prompt if none selected
    try:
        with open("prompts/system_prompt.yaml", "r", encoding="utf-8") as f:
            sys_data = yaml.safe_load(f)
            default_prompt = sys_data.get("template", "")
            # store system prompt separately for tool usage and initialize selected prompt
            st.session_state.system_prompt_text = default_prompt
            st.session_state.selected_prompt_text = default_prompt
    except Exception as e:
        logging.warning(f"Failed to load system prompt: {e}")

    # Auto-load AI App settings from URL 'id' param
    query_params = st.query_params
    if "id" in query_params:
        app_id = query_params["id"]
        if not st.session_state.get("auto_loaded", False):
            try:
                with open("store/ai_app_store.json", "r", encoding="utf-8") as f:
                    ai_app_store = json.load(f)
                for section in ai_app_store.get("AIAppStore", []):
                    for app in section.get("apps", []):
                        url_parts = urlsplit(app.get("url", ""))
                        params = parse_qs(url_parts.query)
                        if params.get("id", [None])[0] == app_id:
                            st.session_state.selected_model = app.get("model", st.session_state.selected_model)
                            st.session_state.temperature = app.get("temperature", st.session_state.temperature)
                            prompt_text = app.get("prompt", "")
                            if prompt_text:
                                st.session_state.selected_prompt_text = prompt_text
                                st.session_state.sidebar_edit_prompt_text = prompt_text
                            tool_config = app.get("tools", {})
                            st.session_state.tool_config = tool_config
                            raw_conf = tool_config.get("mcpServers", tool_config)
                            pending_conf = {}
                            for srv_name, srv_cfg in raw_conf.items():
                                if "url" in srv_cfg:
                                    conf = {"transport": srv_cfg.get("transport", "sse"), "url": srv_cfg["url"]}
                                    for k in ["headers", "timeout", "sse_read_timeout", "session_kwargs"]:
                                        if k in srv_cfg:
                                            conf[k] = srv_cfg[k]
                                else:
                                    conf = {"transport": srv_cfg.get("transport", "stdio"), "command": srv_cfg.get("command"), "args": srv_cfg.get("args")}
                                    for k in ["env", "cwd", "encoding", "encoding_error_handler", "session_kwargs"]:
                                        if k in srv_cfg:
                                            conf[k] = srv_cfg[k]
                                pending_conf[srv_name] = conf
                            st.session_state.pending_mcp_config = pending_conf
                            st.session_state.auto_loaded = True
                            st.session_state.prompt_loaded = True
                            st.session_state.prompt_selectbox = ""
                            st.session_state.tool_selectbox = ""
                            st.session_state.loaded = True
                            st.session_state.app_title = app.get("title", "Universal Agent")
                            success = st.session_state.event_loop.run_until_complete(initialize_session(st.session_state.pending_mcp_config))
                            st.session_state.session_initialized = success
                            if success:
                                st.rerun()
                            break
                        if st.session_state.get("auto_loaded", False):
                            break
            except Exception as e:
                st.error(f"Error loading AI App config: {e}")

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()

try:
    # Suppress async generator cleanup errors
    sys.set_asyncgen_hooks(finalizer=lambda agen: None)
except AttributeError as e:
    logging.error(f'AttributeError: {str(e)}')




# Load MCP config JSON paths for tools selection
MCP_CONFIG_DIR = "mcp-config"
os.makedirs(MCP_CONFIG_DIR, exist_ok=True)
json_paths = glob.glob(f"{MCP_CONFIG_DIR}/*.json")
if not json_paths and not os.path.exists(f"{MCP_CONFIG_DIR}/mcp_config.json"):
    default_config = {"mcpServers": {}}
    with open(f"{MCP_CONFIG_DIR}/mcp_config.json", "w", encoding="utf-8") as f:
        json.dump(default_config, f, indent=2, ensure_ascii=False)
    json_paths = [f"{MCP_CONFIG_DIR}/mcp_config.json"]

st.sidebar.markdown("##### ğŸ’¡ Storeì—ì„œ ì¥ë°”êµ¬ë‹ˆì— ë‹´ì€ Promptì™€ MCP Toolì„ ì¡°í•©í•˜ì—¬ ë‚˜ë§Œì˜ AI Agentë¥¼ ë§Œë“¤ì–´ ë³´ì„¸ìš”.")

# --- Prompt Store (í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° ê´€ë¦¬) ---
# EMP_NO ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê²½ë¡œ ì„¤ì •
PROMPT_CONFIG_DIR = "prompt-config"
logging.debug('Loading configuration from .env')
dotenv_path = find_dotenv()
load_dotenv(dotenv_path)
EMP_NO = os.getenv("EMP_NO", "default_emp_no")
EMP_NAME = os.getenv("EMP_NAME", "default_emp_name")
PROMPT_STORE_PATH = os.path.join(PROMPT_CONFIG_DIR, f"{EMP_NO}.json")

# í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥
if not os.path.exists(PROMPT_STORE_PATH):
    st.sidebar.warning(f"{PROMPT_STORE_PATH} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Prompt Storeì—ì„œ ì¥ë°”êµ¬ë‹ˆ ì €ì¥ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”.")
    prompt_data = {"prompts": {}}
else:
    with open(PROMPT_STORE_PATH, encoding="utf-8") as f:
        prompt_data = json.load(f)


# --- Sidebar for File Selection, Save, and Tool List ---
with st.sidebar:
    
    st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        options=list(OUTPUT_TOKEN_INFO.keys()),
        key="selected_model",
    )
    st.slider(
        "Temperature",
        min_value=0.0,
        max_value=0.5,
        step=0.01,
        key="temperature",
        help="Temperature: ë‚®ì„ìˆ˜ë¡ ê³ ì •ëœ ë‹µë³€, ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€",
    )

    prompts_dict = prompt_data.get("prompts", {})
    prompt_names = list(prompts_dict.keys()) if prompts_dict else ["(ë“±ë¡ëœ í”„ë¡¬í”„íŠ¸ ì—†ìŒ)"]
    if st.session_state.get("auto_loaded", False):
        prompt_names = [""] + prompt_names
    st.selectbox(
        "í”„ë¡¬í”„íŠ¸ ì„ íƒ",
        prompt_names,
        key="prompt_selectbox",
        on_change=load_selected_prompt,
    )
    if st.session_state.get("auto_loaded", False):
        new_prompt_text = st.text_area("í”„ë¡¬í”„íŠ¸ ë‚´ìš©", key="sidebar_edit_prompt_text", height=120)
    else:
        # Ensure selected prompt loaded on initial render
        if "prompt_loaded" not in st.session_state or not st.session_state.prompt_loaded:
            load_selected_prompt()

    # í”„ë¡¬í”„íŠ¸ ì„ íƒ ì‹œ ë°”ë¡œ ì•„ë˜ì— ë‚´ìš© ë³´ì—¬ì£¼ê³  ìˆ˜ì •/ì €ì¥ ê°€ëŠ¥í•˜ê²Œ
    selected_prompt = st.session_state.get("prompt_selectbox")
    if selected_prompt and selected_prompt in prompts_dict:
        # Ensure initial sidebar prompt text is set, then bind text_area to session state without default value
        if "sidebar_edit_prompt_text" not in st.session_state:
            st.session_state.sidebar_edit_prompt_text = prompts_dict[selected_prompt]["prompt"]
        new_prompt_text = st.text_area("í”„ë¡¬í”„íŠ¸ ë‚´ìš©", key="sidebar_edit_prompt_text", height=120)
        if "share_mode" not in st.session_state:
            st.session_state.share_mode = False
        if "clear_share_prompt_title" not in st.session_state:
            st.session_state.clear_share_prompt_title = False
        if st.button("ğŸ“¤ í”„ë¡¬í”„íŠ¸ ê³µìœ ", key="sidebar_share_prompt", use_container_width=True):
            st.session_state.share_mode = True
            if st.session_state.share_mode:
                new_title = st.text_input(
                    "ê³µìœ í•  í”„ë¡¬í”„íŠ¸ ì œëª©ì„ ì…ë ¥í•˜ì„¸ìš”",
                    key="share_prompt_title",
                    value="" if st.session_state.clear_share_prompt_title else st.session_state.get("share_prompt_title", "")
                )
                if st.button("ê³µìœ ", key="share_prompt_confirm", use_container_width=True):
                    global_prompt_store_path = os.path.join("store", "prompt_store.json")
                    if os.path.exists(global_prompt_store_path):
                        with open(global_prompt_store_path, encoding="utf-8") as f:
                            global_prompt_data = json.load(f)
                    else:
                        global_prompt_data = {"prompts": {}}
                    global_prompts_dict = global_prompt_data.get("prompts", {})
                    if not new_title.strip():
                        st.warning("ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    elif new_title in global_prompts_dict:
                        st.warning(f"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì œëª©ì…ë‹ˆë‹¤: {new_title}. ë‹¤ë¥¸ ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        global_prompt_data["prompts"][new_title] = {"prompt": new_prompt_text, "EMP_NO": EMP_NO, "EMP_NAME": EMP_NAME}
                        with open(global_prompt_store_path, "w", encoding="utf-8") as f:
                            json.dump(global_prompt_data, f, indent=2, ensure_ascii=False)
                        st.session_state.saved_msg = f"{new_title} í”„ë¡¬í”„íŠ¸ ê³µìœ  ì™„ë£Œ"
                        st.session_state.share_mode = False
                        st.session_state.clear_share_prompt_title = True
                        st.rerun()
                else:
                    st.session_state.clear_share_prompt_title = False
            else:
                st.session_state.clear_share_prompt_title = False


    tools_list = [{"name": Path(p).stem, "path": p} for p in json_paths]
    tool_names = [t["name"] for t in tools_list]
    default_tool_index = 0
    if "file_path" in st.session_state:
        current_name = Path(st.session_state.file_path).stem
        if current_name in tool_names:
            default_tool_index = tool_names.index(current_name)
    if st.session_state.get("auto_loaded", False):
        tool_names = [""] + tool_names
        default_tool_index = 0
    st.selectbox(
        "MCP Tool ëª©ë¡ ì„ íƒ",
        tool_names,
        key="tool_selectbox",
        index=default_tool_index,
        on_change=load_selected_tool,
    )
    # Load default tool configuration on initial render if not already loaded
    if not st.session_state.get("auto_loaded", False) and not st.session_state.get("loaded", False):
        load_selected_tool()

    # Tool ëª©ë¡ (List & Delete)
    if st.session_state.get("loaded", False):
        mcp = st.session_state.tool_config.get("mcpServers", {})

        st.markdown("MCP Tool ëª©ë¡")
        if not mcp:
            st.warning("ë“±ë¡ëœ ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for name in list(mcp.keys()):
                st.write(f"â€¢ {name}")


    # ì—ì´ì „íŠ¸ ì„¤ì • ì ìš© ë° ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
    if st.button("Agent ìƒì„±í•˜ê¸°", key="create_agent_button", type="primary", use_container_width=True):
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ ì—ì´ì „íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
            progress_bar = st.progress(0)
            # ì„¸ì…˜ ì´ˆê¸°í™”
            st.session_state.session_initialized = False
            st.session_state.agent = None
            progress_bar.progress(30)
            # ì´ˆê¸°í™” ì‹¤í–‰
            success = st.session_state.event_loop.run_until_complete(
                initialize_session(st.session_state.pending_mcp_config)
            )
            progress_bar.progress(100)
            if success:
                st.success("âœ… ì—ì´ì „íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("âŒ ì—ì´ì „íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")
            # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ ìƒíƒœë¥¼ ê°•ì œë¡œ ì„¤ì •í•˜ì—¬ ì±„íŒ…ì„ í™œì„±í™”í•©ë‹ˆë‹¤
            st.session_state.session_initialized = True
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()
    if st.button("ğŸ’¬ ëŒ€í™” ì´ˆê¸°í™”", key="reset_chat", use_container_width=True):
        st.session_state.history = []
        st.session_state.thread_id = random_uuid()
        st.rerun()
    # Add AI App Store registration UI
    if st.button("AI App Store ë“±ë¡", key="aiapp_register_sidebar", use_container_width=True):
        st.session_state.show_aiapp_registration = True
        # Reset AI App form fields when opening the form
        st.session_state.aiapp_new_name = ""
        st.session_state.aiapp_new_desc = ""
        st.session_state.aiapp_new_url = ""
        st.session_state.aiapp_new_hash_tags = ""
        # Remove any previous upload to avoid session_state conflict
        st.session_state.pop("aiapp_icon_upload", None)

    if st.session_state.get("show_aiapp_registration", False):
        st.subheader("ì‹ ê·œ AI App ë“±ë¡")
        aiapp_name = st.text_input("App ì´ë¦„", value=st.session_state.get("aiapp_new_name", ""), key="aiapp_new_name")
        aiapp_desc = st.text_input("App ì„¤ëª…", value=st.session_state.get("aiapp_new_desc", ""), key="aiapp_new_desc")
        # Optional icon upload
        aiapp_icon_file = st.file_uploader("App ì•„ì´ì½˜ (ì„ íƒ, PNG/JPG)", type=["png","jpg","jpeg"], key="aiapp_icon_upload")
        # URL input with validation
        aiapp_url = st.text_input("App ID (ì˜ˆ: Search_Agent)", value=st.session_state.get("aiapp_new_url", ""), key="aiapp_new_url")
        # Optional hashtags input
        aiapp_hash_tags = st.text_input("Hash Tags (ì½¤ë§ˆë¡œ êµ¬ë¶„)", value=st.session_state.get("aiapp_new_hash_tags", ""), key="aiapp_new_hash_tags")
        if st.button("ë“±ë¡", key="aiapp_submit_btn", use_container_width=True):
            AI_APP_STORE_PATH = "store/ai_app_store.json"
            # Load existing AI App store
            if not os.path.exists(AI_APP_STORE_PATH) or os.path.getsize(AI_APP_STORE_PATH) == 0:
                apps_by_type = {"auto": [], "user": []}
            else:
                with open(AI_APP_STORE_PATH, "r", encoding="utf-8") as f:
                    data = json.load(f)
                apps_by_type = {"auto": [], "user": []}
                for section in data.get("AIAppStore", []):
                    t = section.get("type")
                    if t in apps_by_type:
                        apps_by_type[t].extend(section.get("apps", []))
            # Gather inputs
            name = st.session_state.aiapp_new_name.strip()
            desc = st.session_state.aiapp_new_desc.strip()
            url = f"{URL_BASE}{st.session_state.aiapp_new_url.strip()}"
            icon_file = aiapp_icon_file
            tags_raw = st.session_state.aiapp_new_hash_tags.strip()
            hash_tags = [t.strip() for t in tags_raw.split(",") if t.strip()]
            # Check duplicates
            existing_names = [app.get("title", "") for app in apps_by_type["auto"] + apps_by_type["user"]]
            existing_urls = [app.get("url", "") for app in apps_by_type["auto"] + apps_by_type["user"] if app.get("url")]
            # Validate mandatory fields
            if not name or not desc or not url:
                st.error("ì´ë¦„, ì„¤ëª…, URLì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
            elif name in existing_names:
                st.error(f"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” App ì´ë¦„ì…ë‹ˆë‹¤. (ì¤‘ë³µ: {name})")
            else:
                # Validate URL format and characters
                parsed = urlsplit(url)
                if not parsed.scheme or not parsed.netloc:
                    st.error("ìœ íš¨í•œ URLì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ: http://example.com")
                elif any(c in url for c in ['"', "'", '<', '>', ' ']):
                    st.error("URLì— í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                elif url in existing_urls:
                    st.error(f"ì´ë¯¸ ë“±ë¡ëœ URLì…ë‹ˆë‹¤: {url}")
                else:
                    # Save icon if provided
                    icon_name = None
                    if icon_file:
                        ext = Path(icon_file.name).suffix
                        icon_name = f"aiapp_{name}{ext}"
                        icon_dir = os.path.join(ASSETS_DIR, "icons")
                        os.makedirs(icon_dir, exist_ok=True)
                        save_path = os.path.join(icon_dir, icon_name)
                        with open(save_path, "wb") as f:
                            f.write(icon_file.read())
                    # Append new entry
                    apps_by_type["auto"].append({
                        "prompt": st.session_state.selected_prompt_text,
                        "tools": st.session_state.tool_config,
                        "model": st.session_state.selected_model,
                        "temperature": st.session_state.temperature,
                        "title": name,
                        "icon_name": icon_name,
                        "url": url,
                        "hash_tag": hash_tags,
                        "like": 0,
                        "EMP_NO": EMP_NO,
                        "EMP_NAME": EMP_NAME,
                        "description": desc
                    })
                    # Save updated store
                    new_data = {"AIAppStore": [
                        {"type": "auto", "apps": apps_by_type["auto"]},
                        {"type": "user", "apps": apps_by_type["user"]}
                    ]}
                    with open(AI_APP_STORE_PATH, "w", encoding="utf-8") as f:
                        json.dump(new_data, f, indent=2, ensure_ascii=False)
                    st.success("ì‹ ê·œ AI Appì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤! ìƒˆë¡œê³ ì¹¨ í›„ í™•ì¸í•˜ì„¸ìš”.")
                    st.session_state.show_aiapp_registration = False


# --- Main Area ---
title_text = f"ğŸ¤– {st.session_state.get('app_title', 'Universal Agent')}"
st.title(title_text)
st.markdown("---")

# í•˜ë‹¨ ì €ì¥ ë©”ì‹œì§€ ì¶œë ¥
with st.sidebar:
    if st.session_state.get("saved_msg"):
        st.success(st.session_state.pop("saved_msg"))

# Monkey-patch MultiServerMCPClient.__aexit__ to suppress 'no running event loop' errors during cleanup
_orig_mcp_aexit = MultiServerMCPClient.__aexit__
async def _safe_mcp_aexit(self, exc_type, exc_val, exc_tb):
    try:
        await _orig_mcp_aexit(self, exc_type, exc_val, exc_tb)
    except RuntimeError:
        # Suppress errors when event loop is closed
        pass
    except Exception:
        # Suppress any cleanup-related errors
        pass
MultiServerMCPClient.__aexit__ = _safe_mcp_aexit

# Monkey-patch stdio_client to suppress 'no running event loop' errors
_orig_stdio_client = _stdio.stdio_client
@asynccontextmanager
async def safe_stdio_client(server, errlog=sys.stderr):
    try:
        async with _orig_stdio_client(server, errlog) as (read_stream, write_stream):
            yield read_stream, write_stream
    except RuntimeError:
        # Suppress errors when event loop is closed
        pass
    except Exception:
        # Suppress any cleanup-related errors
        pass
# Override stdio_client with the safe version
_stdio.stdio_client = safe_stdio_client

# Also patch the imported stdio_client in langchain_mcp_adapters.client
import langchain_mcp_adapters.client as _lcmcp_client
_lcmcp_client.stdio_client = safe_stdio_client

# Auto-load AI App settings from URL 'id' param
query_params = st.query_params
if "id" in query_params:
    app_id = query_params["id"]
    if not st.session_state.get("auto_loaded", False):
        try:
            with open("store/ai_app_store.json", "r", encoding="utf-8") as f:
                ai_app_store = json.load(f)
            for section in ai_app_store.get("AIAppStore", []):
                for app in section.get("apps", []):
                    url_parts = urlsplit(app.get("url", ""))
                    params = parse_qs(url_parts.query)
                    if params.get("id", [None])[0] == app_id:
                        # apply app config
                        st.session_state.selected_model = app.get("model", st.session_state.selected_model)
                        st.session_state.temperature = app.get("temperature", st.session_state.temperature)
                        prompt_text = app.get("prompt", "")
                        if prompt_text:
                            st.session_state.selected_prompt_text = prompt_text
                            st.session_state.sidebar_edit_prompt_text = prompt_text
                        tool_config = app.get("tools", {})
                        st.session_state.tool_config = tool_config
                        raw_conf = tool_config.get("mcpServers", tool_config)
                        pending_conf = {}
                        for srv_name, srv_cfg in raw_conf.items():
                            if "url" in srv_cfg:
                                conf = {"transport": srv_cfg.get("transport", "sse"), "url": srv_cfg["url"]}
                                for k in ["headers", "timeout", "sse_read_timeout", "session_kwargs"]:
                                    if k in srv_cfg:
                                        conf[k] = srv_cfg[k]
                            else:
                                conf = {"transport": srv_cfg.get("transport", "stdio"), "command": srv_cfg.get("command"), "args": srv_cfg.get("args")}
                                for k in ["env", "cwd", "encoding", "encoding_error_handler", "session_kwargs"]:
                                    if k in srv_cfg:
                                        conf[k] = srv_cfg[k]
                            pending_conf[srv_name] = conf
                        st.session_state.pending_mcp_config = pending_conf
                        st.session_state.auto_loaded = True
                        st.session_state.prompt_loaded = True
                        st.session_state.prompt_selectbox = ""
                        st.session_state.tool_selectbox = ""
                        st.session_state.loaded = True
                        st.session_state.app_title = app.get("title", "Universal Agent")
                        success = st.session_state.event_loop.run_until_complete(initialize_session(st.session_state.pending_mcp_config))
                        st.session_state.session_initialized = success
                        if success:
                            st.rerun()
                        break
                if st.session_state.get("auto_loaded", False):
                    break
        except Exception as e:
            st.error(f"Error loading AI App config: {e}")

# --- Main Chat Area ---
if not st.session_state.session_initialized:
    st.info("âš ï¸ MCP ì„œë²„ì™€ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ Promptì™€ MCP Toolì„ ì„ íƒí•˜ê³  'Agent ìƒì„±í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")

# --- ëŒ€í™” ê¸°ë¡ ì¶œë ¥ ---
print_message()

# --- ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬ ---
user_query = st.session_state.pop("user_query", None) or st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_query:
    if st.session_state.session_initialized:
        st.chat_message("user", avatar="ğŸ§‘ğŸ»").write(user_query)
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            tool_placeholder = st.empty()
            text_placeholder = st.empty()
            
            # ì§„í–‰ ìƒíƒœ í‘œì‹œê¸° ì¶”ê°€
            progress_placeholder = st.empty()
            with progress_placeholder.container():
                st.write("ğŸ” Agentê°€ ë„êµ¬ë¥¼ í†µí•´ ë‹µë³€ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")
                progress_bar = st.progress(0)
                
                # ë„êµ¬ í˜¸ì¶œ ë° ì²˜ë¦¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§
                def update_progress():
                    pending_count = len(st.session_state.get("pending_tool_calls", []))
                    if pending_count > 0:
                        return 30  # ë„êµ¬ í˜¸ì¶œ ì‹œì‘
                    
                    response_count = len(st.session_state.get("tool_responses", {}))
                    if response_count > 0:
                        return 70  # ë„êµ¬ ì‘ë‹µ ì²˜ë¦¬ ì¤‘
                        
                    return 100  # ì™„ë£Œ
                
                # ì¦‰ì‹œ ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
                progress_bar.progress(10)
            
            # ì‹¤ì œ ì¿¼ë¦¬ ì²˜ë¦¬
            resp, final_text, final_tool = (
                st.session_state.event_loop.run_until_complete(
                    process_query(
                        user_query,
                        text_placeholder,
                        tool_placeholder,
                        st.session_state.timeout_seconds,
                    )
                )
            )
            
            # ì§„í–‰ í‘œì‹œê¸° ì œê±°
            progress_placeholder.empty()
            
        if "error" in resp:
            st.error(resp["error"])
        else:
            st.session_state.history.append({"role": "user", "content": user_query})
            # Generate follow-up questions and add to assistant message
            openai_api_key = os.getenv("OPENAI_API_KEY", "")
            raw_base = os.getenv("OPENAI_API_BASE", "https://api.openai.com")
            parsed = urlsplit(raw_base)
            openai_api_base = f"{parsed.scheme}://{parsed.netloc}/v1"
            followup_llm = get_followup_llm(
                st.session_state.selected_model,
                0.3,
                openai_api_key,
                openai_api_base,
            )
            followups = st.session_state.event_loop.run_until_complete(
                generate_followups(followup_llm, final_text)
            )
            st.session_state.history.append(
                {"role": "assistant", "content": final_text, "followups": followups}
            )
            if final_tool.strip():
                st.session_state.history.append(
                    {"role": "assistant_tool", "content": final_tool}
                )
            st.rerun()
    else:
        st.warning(
            "âš ï¸ MCP ì„œë²„ì™€ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ Promptì™€ MCP Toolì„ ì„ íƒí•˜ê³  'Agent ìƒì„±í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."
        )
